---
title: "Parallel in R - basics"
author: "Max Gordon"
date: "February 14, 2015"
output:
  ioslides_presentation:
    logo: ki_logo_square.png
    widescreen: yes
---

## Why go parallel?

* Bought a computer after 2010
* Poor coding skills
* Don't know C++
* C++ isn't enough

**Amdal's law:**
$$\text{Maximum speed-up} = \lim_{p\to\infty}\frac{1}{\frac{1-\alpha}{p}-\alpha}=\frac{1}{\alpha}$$

$\alpha = \text{non-parallelizable parts}$

$p = \text{no. processors}$


## Parallel in R

**Basics & tools**

1. MapReduce
2. Thinking lapply
3. Package: `parallel`
4. Package: `foreach`
5. Fork or sock?

**Trouble shooting**

1. Caching
2. Debugging in threads
3. Load balancing

## MapReduce - programming model

**Concept**

1. The Map - Map(k1,v1) --> list(k2,v2)
2. Shuffle
3. The Reduce - Reduce(k2, list (v2)) --> list(v3)

**Interpretation**

* Map: calculate the basic core statistic.
* Reorder stuff so reduce can find it
* Reduce: aggregate the statistic from Map into what we want.

## MapReduce - Schematic {.flexbox .vcenter}

![The MapReduce schematic](map_reduce_at_home.jpg)

Curtesy of: http://gerardnico.com/wiki/algorithm/map_reduce

## Learning lapply

* Core R
* Simple
* Each element is independent

```{r}
lapply(1:3, function(x) c(x, x^2, x^3))
```

## Package: `parallel`

<div class="columns-2">
```{r}
library(parallel)
no_cores <- detectCores()
base <- 2

# Initiate cluster
cl<-makeCluster(no_cores)
clusterExport(cl, "base")

# Run
parLapply(cl, 
          2:4, 
          function(exponent) 
            base^exponent)

# Finish
stopCluster(cl)
```
</div>


## Package: `parallel` with parSapply {.smaller}


```{r Initiate_pr_cluster, echo=FALSE}
no_cores <- detectCores()
base <- 2
cl<-makeCluster(no_cores)
clusterExport(cl, "base")
```

```{r}
# Simple output
parSapply(cl, 2:4, 
          function(exponent) 
            base^exponent)

# Matrix output with names
parSapply(cl, as.character(2:4), 
          function(exponent){
            x <- as.numeric(exponent)
            c(base = base^x, self = x^x)
          })
```

```{r, echo=FALSE}
stopCluster(cl)
```

## Package: `foreach`

<div class="columns-2">
```{r, message=FALSE, error=TRUE}
library(foreach)
library(doParallel)

cl<-makeCluster(no_cores)

# Do the foreach
registerDoParallel(cl)
foreach(exponent = 2:4, 
        .combine = c)  %dopar%  
  base^exponent

# Pass two variables
foreach(exponent = 2:4,
        base = 2:4, 
        .combine = c) %dopar% 
  base^exponent

stopCluster(cl)
```
</div>

## Package: `foreach` variable scope

```{r Initiate_cluster, echo=FALSE}
cl<-makeCluster(no_cores)
registerDoParallel(cl)
```

```{r, error=TRUE}
test <- function(export = NULL){
  foreach(exponent = 2:4, 
          .export = export,
          .combine = c)  %dopar%  
    base^exponent 
}
test()

# We need to export "base"-variable to avoid error
test("base")
```

## Package: `foreach` creating a lapply result

```{r}
# Unexpected list?
foreach(exponent = 2:4, 
        base = 2:4,
        .combine = list) %dopar% 
  base^exponent
```

## Package: `foreach` creating a lapply result cont.

```{r}
foreach(exponent = 2:4, 
        base = 2:4,
        .combine = list,
        .multicombine = TRUE) %dopar% 
  base^exponent
```

## Fork or sock?

**FORK**

Name: "to divide in branches, go separate ways"<br />
System: Unix/Mac<br />
Environment: Link all

**PSOCK**

Name: Parallel Socket Cluster<br />
System: Windows<br />
Environment: Empty

## Fork or sock? cont. 

**From Ubuntu 14:10**

```{r, eval=FALSE}
cl<-makeCluster(no_cores)
clusterExport(cl, "a")
clusterEvalQ(cl, library(pryr))

### <b>
parSapply(cl, X = 1:10, function(x) {address(a)}) == address(a)
# [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
### </b>
stopCluster(cl)
```

## Fork or sock? cont. 

**From Ubuntu 14:10**

```{r, eval=FALSE}
cl<-makePSOCKcluster(no_cores)
clusterEvalQ(cl, library(pryr))
clusterExport(cl, "a")

### <b>
parSapply(cl, X = 1:10, function(x) address(a)) == address(a)
# [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
### </b>
stopCluster(cl)

cl<-makeForkCluster(no_cores)
### <b>
parSapply(cl, X = 1:10, function(x) address(a)) == address(a)
# [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
### </b>
stopCluster(cl)
```

## Fork or sock? cont. 

**From Ubuntu 14:10**

No memory corruption even with shared

```{r, eval=FALSE}
b <- 0
cl<-makeForkcluster(2)
clusterExport(cl, "b")

### <b>
parSapply(cl, X = 1:10, function(x) {b <- b + 1; b})
# [1] 1 1 1 1 1 1 1 1 1 1
parSapply(cl, X = 1:10, function(x) {b <<- b + 1; b})
# [1] 1 2 3 4 5 1 2 3 4 5
b
# [1] 0
### </b>
```

## A few tips

**Save one core for the system**

```{r, eval=FALSE}
max(1, detectCores() - 1)
```

**Macroparallel (unless memory issues)**

**Microparallel `gputools`**

# Trouble shooting

## Debugging

* Avoid `stop()`
* Setting `makeCluster(..., outfile = "par_out.txt")`
* Each element has a unique error file

## Caching

**Save as you go**

1. Do a digest of settings + function
2. Check if file.exists()
3. Load if exists otherwise run funciton on data and save into file

or use `R.cache`-package

## Caching with digest

```{r, echo=FALSE, results='hide'}
file.remove(list.files(pattern = "Cache.+\\.Rdata"))
```

<div class="columns-2">
```{r}
cacheParallel <- function(){
  vars <- 1:2
  tmp <- clusterEvalQ(cl, 
                      library(digest))
  
  parSapply(cl, vars, function(var){
    fn <- function(a) a^2
    ### <b>
    dg <- digest(list(fn, var))
    cache_fn <- 
      sprintf("Cache_%s.Rdata", 
              dg)
    if (file.exists(cache_fn)){
      load(cache_fn)
    }else{
      var <- fn(var); 
      Sys.sleep(5)
      save(var, file = cache_fn)
    }
    ### </b>
    return(var)
  })
}
```
</div>

## Caching with digest cont.

<div class="columns-2">
```{r}
system.time(out <- cacheParallel())
out
system.time(out <- cacheParallel())
out
```
</div>

```{r, echo=FALSE, results='hide'}
file.remove(list.files(pattern = "Cache.+\\.Rdata"))
```

## Load balancing - workload

**parLapply under the hood**

```{r, eval=FALSE}
function (cl = NULL, X, fun, ...) 
{
    cl <- defaultCluster(cl)
    do.call(c, clusterApply(cl, x = splitList(X, length(cl)), 
        fun = lapply, fun, ...), quote = TRUE)
}  
```

**Note:** <code>splitList(X, length(cl))</code>

## Load balancing - memory

* Remember to use **forks**
* memory.limit()/memory.size() = max cores
* remove any old copies through **rm()**
* force return memory through **gc()**
* try to do high-memory load parallel with low memory
* skip parallel if limit reached

```{r Stop_cluster, echo=FALSE}
stopCluster(cl)
```

## Load balancing - advanced {.smaller}

**Basic setup**
<div class="columns-2">
```{r, eval=FALSE}
> rm(list=ls())
> library(pryr)
> library(magrittr)
> a <- matrix(1, ncol=10^4*2, nrow=10^4)
> object_size(a)
1.6 GB
> system.time(mean(a))
   user  system elapsed 
  0.338   0.000   0.337 
> system.time(mean(a + 1))
   user  system elapsed 
  0.490   0.084   0.574 
> library(parallel)
> cl <- makeCluster(4, type = "PSOCK")
> system.time(clusterExport(cl, "a"))
### <b>
   user  system elapsed 
  5.253   0.544   7.289 
### </b>
> system.time(parSapply(cl, 1:8, 
                        function(x) mean(a + 1)))
### <b>
   user  system elapsed 
  0.008   0.008   3.365 
### </b>
> stopCluster(cl); gc();
> cl <- makeCluster(4, type = "FORK")
> system.time(parSapply(cl, 1:8, 
                        function(x) mean(a + 1)))
### <b>
   user  system elapsed 
  0.009   0.008   3.123 
### </b>
> stopCluster(cl)
```

</div>

<div style="font-size: .5em;">Note the gc() that is needed in order to avoid:
<pre style="font-size: inherit;">
Error in mcfork() : 
  unable to fork, possible reason: Cannot allocate memory
  </pre>
</div>
  
## Load balancing - advanced

**The PSOCK problem**
```{r, eval=FALSE}
> cl <- makeCluster(8, type = "PSOCK")
> system.time(clusterExport(cl, "a"))
   user  system elapsed 
 10.576   1.263  15.877 
> system.time(parSapply(cl, 1:8, function(x) mean(a + 1)))
### <b>
Error in checkForRemoteErrors(val) : 
  8 nodes produced errors; first error: cannot allocate vector of size 1.5 Gb
### </b>
Timing stopped at: 0.004 0 0.389 
> stopCluster(cl)
> cl <- makeCluster(8, type = "FORK")
> system.time(parSapply(cl, 1:8, function(x) mean(a + 1)))
   user  system elapsed 
  0.014   0.016   3.735 
> stopCluster(cl)
```

## Load balancing - advanced

**Even FORKs won't save you in the end**
```{r, eval=FALSE}
> a <- matrix(1, ncol=10^4*2.1, nrow=10^4)
> cl <- makeCluster(8, type = "FORK")
> parSapply(cl, 1:8, function(x) {
+   b <- a + 1
+   mean(b)
+   })
### <b>
Error in unserialize(node$con) : error reading from connection
### </b>
```

# The end

